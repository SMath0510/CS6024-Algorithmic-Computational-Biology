{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ec99bf-cfa7-448a-97a4-99e5853be0a3",
   "metadata": {},
   "source": [
    "# Script to get HIPPIE.txt to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59bae4a4-3d91-4d41-a0ea-b5a29a94e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb4269a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_txt_file_path = \"database/hippie_v2_2.txt\" \n",
    "database_csv_file_path = \"database/hippie_v2_2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d31a7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful. CSV file created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    with open(database_txt_file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "        lines = content.strip().split('\\n')\n",
    "        csv_writer = csv.writer(open(database_csv_file_path, \"w\", newline=''))\n",
    "        for line in lines:\n",
    "            row = line.split('\\t')\n",
    "            csv_writer.writerow(row)\n",
    "        print(\"Conversion successful. CSV file created.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found at the specified path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6737a-223a-463f-86f1-37480be15c38",
   "metadata": {},
   "source": [
    "# HIPPIE (v2.2)\n",
    "\n",
    "* Only first 5 columns are useful (I hope).\n",
    "* Column 1 and 3 --> Strings which contain UNIPROT_ID of the proteins\n",
    "* Columns 2 and 4 --> Integers which are also some form of unique ID (but not UniProt)\n",
    "* Column 5 --> confidence interval or probability of interaction   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d50225a5-c270-40ab-96af-75ff4de67672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0      1            2     3     4\n",
      "0  AL1A1_HUMAN    216  AL1A1_HUMAN   216  0.76\n",
      "1   ITA7_HUMAN   3679   ACHA_HUMAN  1134  0.73\n",
      "2   NEB1_HUMAN  55607   ACTG_HUMAN    71  0.65\n",
      "3   SRGN_HUMAN   5552   CD44_HUMAN   960  0.63\n",
      "4   GRB7_HUMAN   2886  ERBB2_HUMAN  2064  0.90\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(database_csv_file_path, delimiter=',', usecols=range(5),header = None)\n",
    "data = data.dropna()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89f30c-b6f6-4839-aeac-34574c90d25f",
   "metadata": {},
   "source": [
    "### Filtering the Dataset based on thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f7b441f-37b0-40f7-9f1f-0c42509fe7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(data, upper_threshold, lower_threshold, random_sample_fraction_upper, random_sample_fraction_lower):\n",
    "    upper_data = data[data.iloc[:, -1] > upper_threshold]\n",
    "    lower_data = data[data.iloc[:, -1] < lower_threshold]\n",
    "    \n",
    "    upper_data_length = int(random_sample_fraction_upper * upper_data.shape[0])\n",
    "    lower_data_length = int(random_sample_fraction_lower * lower_data.shape[0])\n",
    "    \n",
    "    upper_data_sampled = upper_data.sample(n=upper_data_length, random_state=42)  \n",
    "    lower_data_sampled = lower_data.sample(n=lower_data_length, random_state=42) \n",
    "\n",
    "    filtered_data = pd.concat([upper_data_sampled, lower_data_sampled])\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92f3547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_threshold = 0.85  # Set any confidence probability\n",
    "lower_threshold = 0.5\n",
    "random_sample_fraction_upper = 0.5\n",
    "random_sample_fraction_lower = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a4b8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0      1            2      3     4\n",
      "470    UB2L3_HUMAN   7332    CBL_HUMAN    867  0.90\n",
      "39720   CNBP_HUMAN   7555   EBP2_HUMAN  10969  0.86\n",
      "12594   DEDD_HUMAN   9191  CFLAR_HUMAN   8837  0.89\n",
      "40931  DTBP1_HUMAN  84062  BL1S1_HUMAN   2647  0.89\n",
      "1339    PLK1_HUMAN   5347   PSA3_HUMAN   5684  0.88\n"
     ]
    }
   ],
   "source": [
    "filtered_df = filter_dataframe(data, upper_threshold, lower_threshold,random_sample_fraction_upper, random_sample_fraction_lower)\n",
    "\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0882a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with interaction probability < lower_threshold: 4638\n",
      "Number of rows with interaction probability > upper_threshold: 7727\n"
     ]
    }
   ],
   "source": [
    "lower_count = len(filtered_df[filtered_df.iloc[:, -1] < lower_threshold])\n",
    "upper_count = len(filtered_df[filtered_df.iloc[:, -1] > upper_threshold])\n",
    "\n",
    "print(f\"Number of rows with interaction probability < lower_threshold: {lower_count}\")\n",
    "print(f\"Number of rows with interaction probability > upper_threshold: {upper_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f07dc1c-dde1-4c30-be71-d1b742820f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_map(dataframe):\n",
    "    interaction_map = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        protein_pair = (row[0], row[2]) \n",
    "        probability = row[4] \n",
    "        interaction_map[protein_pair] = probability\n",
    "    return interaction_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f44d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of interacting pairs TOTAL: 11752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interaction_map = create_interaction_map(filtered_df)\n",
    "print(f\" Number of interacting pairs TOTAL: {len(interaction_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f48423-d9d4-458d-ad41-7414ac5a58dd",
   "metadata": {},
   "source": [
    "## Scrapping from the UniProt Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf6d6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from Bio import SeqIO\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc48589-9c02-4c28-9785-558813d014ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable nested asyncio for environments like Jupyter notebooks\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a5312",
   "metadata": {},
   "source": [
    "### Asynchronous Implementation of Protein Sequence Fetching from Protein Name/ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e973f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def fetch_sequence(session, uniprot_id, retry=3):\n",
    "    url = f\"http://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            async with session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.text()\n",
    "                    Seq = StringIO(data)\n",
    "                    p_seq = list(SeqIO.parse(Seq, 'fasta'))\n",
    "                    if p_seq:\n",
    "                        # print(f\"Found sequence for {uniprot_id}\")\n",
    "                        return uniprot_id, str(p_seq[0].seq)\n",
    "                    else:\n",
    "                        print(f\"Sequence not found for UniProt ID: {uniprot_id}\")\n",
    "                        return uniprot_id, None\n",
    "                else:\n",
    "                    print(f\"Error fetching sequence for UniProt ID: {uniprot_id}. Status code: {response.status}\")\n",
    "                    return uniprot_id, None\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error connecting to server for UniProt ID: {uniprot_id}. Retrying...\")\n",
    "    return uniprot_id, None\n",
    "\n",
    "async def scrape_protein_sequences(unique_ids):\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for uniprot_id_str in unique_ids:\n",
    "            uniprot_ids = uniprot_id_str.split(\",\")\n",
    "            for uniprot_id in uniprot_ids:\n",
    "                tasks.append(fetch_sequence(session, uniprot_id.strip()))\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "async def filter_dataframe_and_scrape(filtered_df):\n",
    "    try:\n",
    "        data = filtered_df.iloc[:, [0, 2]].copy()\n",
    "        unique_ids = set(data.iloc[:, 0].tolist() + data.iloc[:, 1].tolist())\n",
    "        protein_sequences = await scrape_protein_sequences(unique_ids)\n",
    "        return {uniprot_id: sequence for uniprot_id, sequence in protein_sequences if sequence is not None}\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        # Assuming filtered_df is defined somewhere\n",
    "        protein_sequences = await filter_dataframe_and_scrape(filtered_df)\n",
    "        return protein_sequences\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4718e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sequence for UniProt ID: 1C04_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: 1B27_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: MTR1_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: COM1_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: NAP1_HUMAN. Status code: 400\n",
      "Sequence not found for UniProt ID: GCNT6_HUMAN\n",
      "Error fetching sequence for UniProt ID: APC2_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: GCP2_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: DCD_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: ARF1_HUMAN. Status code: 400\n",
      "Sequence not found for UniProt ID: UBP41_HUMAN\n",
      "Error fetching sequence for UniProt ID: 1B57_HUMAN. Status code: 400\n",
      "Sequence not found for UniProt ID: CGHB_HUMAN\n",
      "Error fetching sequence for UniProt ID: GBLP_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: IRK2_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: RAC1_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: DSS1_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: CCR4_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: COG7_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: RHBD1_HUMAN. Status code: 400\n",
      "Error fetching sequence for UniProt ID: CALM_HUMAN. Status code: 400\n",
      "Sequence not found for UniProt ID: CU077_HUMAN\n",
      "Sequence not found for UniProt ID: HSP71_HUMAN\n"
     ]
    }
   ],
   "source": [
    "protein_sequences = asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa616bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of protein sequences: 6391\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of protein sequences: {len(protein_sequences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e24a3",
   "metadata": {},
   "source": [
    "## Applying CD HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2c1d0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "cd-hit is already the newest version (4.8.1-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install cd-hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3451b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fasta_file_path = \"fasta_files/input.fasta\"\n",
    "output_fasta_file_path = \"fasta_files/output.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8b631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta_from_dict(protein_dict, file_path = input_fasta_file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for uniprot_id, sequence in protein_dict.items():\n",
    "            f.write(f'>{uniprot_id}\\n')  # Write UniProt ID as header\n",
    "            f.write(f'{sequence}\\n')      # Write protein sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caa5a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fasta_from_dict(protein_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a025ca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Program: CD-HIT, V4.8.1 (+OpenMP), Aug 20 2021, 08:39:56\n",
      "Command: cd-hit -i fasta_files/input.fasta -o\n",
      "         fasta_files/output.fasta -c 0.4 -n 2\n",
      "\n",
      "Started: Sat Apr 27 20:03:04 2024\n",
      "================================================================\n",
      "                            Output                              \n",
      "----------------------------------------------------------------\n",
      "total seq: 6391\n",
      "longest and shortest : 34350 and 44\n",
      "Total letters: 4158200\n",
      "Sequences have been sorted\n",
      "\n",
      "Approximated minimal memory consumption:\n",
      "Sequence        : 4M\n",
      "Buffer          : 1 X 17M = 17M\n",
      "Table           : 1 X 0M = 0M\n",
      "Miscellaneous   : 0M\n",
      "Total           : 23M\n",
      "\n",
      "Table limit with the given memory limit:\n",
      "Max number of representatives: 787719\n",
      "Max number of word counting entries: 97120880\n",
      "\n",
      "comparing sequences from          0  to       6391\n",
      "......\n",
      "     6391  finished       5073  clusters\n",
      "\n",
      "Approximated maximum memory consumption: 32M\n",
      "writing new database\n",
      "writing clustering information\n",
      "program completed !\n",
      "\n",
      "Total CPU time 555.02\n"
     ]
    }
   ],
   "source": [
    "!cd-hit -i $input_fasta_file_path -o $output_fasta_file_path -c 0.4 -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2ad0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(file_path):\n",
    "    protein_sequences = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        protein_id = None\n",
    "        sequence = ''\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if protein_id is not None:\n",
    "                    protein_sequences[protein_id] = sequence\n",
    "                protein_id = line[1:].split()[0]  # Extract UniProt ID\n",
    "                sequence = ''\n",
    "            else:\n",
    "                sequence += line\n",
    "        # Add the last protein sequence\n",
    "        if protein_id is not None:\n",
    "            protein_sequences[protein_id] = sequence\n",
    "    return protein_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d01abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_sequences = read_fasta(output_fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72c089c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of protein sequences 5073\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final number of protein sequences {len(protein_sequences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746e739",
   "metadata": {},
   "source": [
    "### Getting Protein Features from the Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a0a0923-a7b2-4d98-a8be-7192b0ec6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from aaindex import aaindex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4ce481a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_AAID():\n",
    "    AAID = []\n",
    "    url = \"https://www.genome.jp/aaindex/AAindex/list_of_indices\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    soup_string = str(soup)\n",
    "    soup_lines = soup_string.split('\\n')\n",
    "    \n",
    "    for line in soup_lines[5:]:\n",
    "        AAID.append(line[:10])\n",
    "    \n",
    "    return AAID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b68f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAID = get_AAID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fed4fce5-4a98-4ea9-9d90-519ed65d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(name):\n",
    "    dict = aaindex1[name].values\n",
    "    return dict\n",
    "    \n",
    "def get_data(AAID):\n",
    "    data = []\n",
    "    for name in AAID[:-1]:\n",
    "        dictionary = get_dictionary(name)\n",
    "        data.append(dictionary)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8f98244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(AAID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55603b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name     A     C     D     E     F     G     H     I     K  ...  \\\n",
      "0  ANDN920101  4.35  4.65  4.76  4.29  4.66  3.97  4.63  3.95  4.36  ...   \n",
      "1  ARGP820101  0.61  1.07  0.46  0.47  2.02  0.07  0.61  2.22  1.15  ...   \n",
      "2  ARGP820102  1.18  1.89  0.05  0.11  1.96  0.49  0.31  1.45  0.06  ...   \n",
      "3  ARGP820103  1.56  1.23  0.14  0.23  2.03  0.62  0.29  1.67  0.15  ...   \n",
      "4  BEGF750101  1.00  0.06  0.44  0.73  0.60  0.35  0.60  0.73  0.60  ...   \n",
      "\n",
      "      M     N     P     Q     R     S     T     V     W     Y  \n",
      "0  4.52  4.75  4.44  4.37  4.38  4.50  4.35  3.95  4.70  4.60  \n",
      "1  1.18  0.06  1.95  0.00  0.60  0.05  0.05  1.32  2.65  1.88  \n",
      "2  2.67  0.23  0.76  0.72  0.20  0.97  0.84  1.08  0.77  0.39  \n",
      "3  2.96  0.27  0.76  0.51  0.45  0.81  0.91  1.14  1.08  0.68  \n",
      "4  1.00  0.35  0.06  0.44  0.52  0.35  0.44  0.82  0.73  0.44  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Name'] = AAID[:-1]\n",
    "df = df[['Name'] + [col for col in df.columns if col != 'Name']]\n",
    "df.drop('-', axis=1, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08b7aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMAKKPPKPAPRRIFQERLKITALPLYFEGFLLIKRSGYREYEHYWTELRGTTLFFYTDKKSIIYVDKLDIVDLTCLTEQNSTEKNCAKFTLVLPKEEVQLKTENTESGEEWRGFILTVTELSVPQNVSLLPGQVIKLHEVLEREKKRRIETEQSTSVEKEKEPTEDYVDVLNPMPACFYTVSRKEATEMLQKNPSLGNMILRPGSDSRNYSITIRQEIDIPRIKHYKVMSVGQNYTIELEKPVTLPNLFSVIDYFVKETRGNLRPFICSTDENTGQEPSMEGRSEKLKKNPHIA\n"
     ]
    }
   ],
   "source": [
    "print(protein_sequences[\"STAP1_HUMAN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd734040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_sum(sequence, df, sequence_length):\n",
    "    scaled_df = df.copy()\n",
    "    for amino_acid, count in sequence.items():\n",
    "        if amino_acid in df.columns:\n",
    "            scaled_df[amino_acid] *= count\n",
    "            \n",
    "    columns_to_sum = scaled_df.columns[1:]\n",
    "\n",
    "    summed_rows = scaled_df[columns_to_sum].sum(axis=1)\n",
    "    return summed_rows / sequence_length\n",
    "\n",
    "def get_results(protein_sequences, df):\n",
    "    results = {}\n",
    "\n",
    "    for uniprot_id, sequence in protein_sequences.items():\n",
    "        amino_acid_counts = {amino_acid: sequence.count(amino_acid) for amino_acid in set(sequence)}\n",
    "        sequence_length = len(sequence)\n",
    "        weighted_sum = calculate_weighted_sum(amino_acid_counts, df, sequence_length)\n",
    "        results[uniprot_id] = weighted_sum\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3645e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(protein_sequences, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50c0304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of proteins 5073\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of proteins {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036a220-c7aa-4baf-9e25-9e61dedbec80",
   "metadata": {},
   "source": [
    "# RESULT_DF gives the UniProt ID and 566 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23f7872e-84f0-4dcc-a349-acc021a3df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_resultDF(results):\n",
    "    data_rows = []\n",
    "\n",
    "    for uniprot_id, result in results.items():\n",
    "        data_row = {'UniProt ID': uniprot_id}\n",
    "        for i, value in enumerate(result):\n",
    "            data_row[f'Feature_{i+1}'] = value\n",
    "        data_rows.append(data_row)\n",
    "\n",
    "    result_df = pd.DataFrame(data_rows)\n",
    "    result_df.dropna()\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebe791d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UniProt ID  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
      "0   BAG4_HUMAN   4.374726   0.853720   0.809934   0.855011   0.478293   \n",
      "1   NXT1_HUMAN   4.387643   0.848214   1.002143   1.046214   0.584929   \n",
      "2   PPLA_HUMAN   4.654808   1.190385   1.515192   1.517500   0.705769   \n",
      "3  EIF3K_HUMAN   4.369495   0.930642   1.098761   1.138394   0.624083   \n",
      "4  PRR14_HUMAN   4.358410   0.934154   0.959949   0.998205   0.516547   \n",
      "\n",
      "   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_557  Feature_558  \\\n",
      "0   0.686980   0.772363   0.465024  77.780525  ...    10.301969    15.777832   \n",
      "1   0.747857   0.681286   0.434214  82.625714  ...    10.735714    16.777364   \n",
      "2   0.847692   0.679231   0.455519  97.686538  ...    12.846154    19.524250   \n",
      "3   0.748624   0.668028   0.432670  85.338991  ...    11.261468    17.291573   \n",
      "4   0.699795   0.735060   0.459689  80.735385  ...    10.914530    16.345875   \n",
      "\n",
      "   Feature_559  Feature_560  Feature_561  Feature_562  Feature_563  \\\n",
      "0    11.385120    19.610503    29.843033     6.008759    22.546915   \n",
      "1    11.871429    20.342857    31.701050     6.245221    23.793314   \n",
      "2    14.076923    23.442308    35.635154     6.763788    26.642000   \n",
      "3    12.449541    20.986239    32.486849     6.206780    24.097817   \n",
      "4    11.897436    19.569231    29.730333     6.002499    22.911407   \n",
      "\n",
      "   Feature_564  Feature_565  Feature_566  \n",
      "0    -0.338893     9.538492     4.255190  \n",
      "1    -0.390500     9.713200     3.540300  \n",
      "2    -0.469673    10.789250     3.515077  \n",
      "3    -0.402780     9.772028     3.057280  \n",
      "4    -0.356347     9.783950     4.792940  \n",
      "\n",
      "[5 rows x 567 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_df = get_resultDF(results)\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6063c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of protiens 5073\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final number of protiens {len(result_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efd195d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_combined_vector(protein1, protein2, result_df):\n",
    "    # Assuming result_df is defined as your DataFrame and protein1, protein2 are defined\n",
    "\n",
    "    # Retrieve rows based on UniProt ID\n",
    "    row1 = result_df.loc[result_df['UniProt ID'] == protein1, result_df.columns[1:]].values.tolist()\n",
    "    row2 = result_df.loc[result_df['UniProt ID'] == protein2, result_df.columns[1:]].values.tolist()\n",
    "\n",
    "    # print(row1, row2)\n",
    "    # Check if rows exist\n",
    "    results_row = []\n",
    "    if row1 and row2:\n",
    "        # Calculate the average of corresponding elements\n",
    "        results_row = [(x + y) * 0.5 for x, y in zip(row1[0], row2[0])]\n",
    "        # print(\"Results Row:\", results_row)\n",
    "    elif not row1:\n",
    "        print(f\"Not found {protein1}\")\n",
    "    elif not row2:\n",
    "        print(f\"Not found {protein2}\")\n",
    "    else:\n",
    "        print(f\"Not found {protein1} and {protein2}\")\n",
    "\n",
    "    return results_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0071179",
   "metadata": {},
   "source": [
    "## Save this later in a file and load it types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9bc409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_pair_df(filtered_df, result_df):\n",
    "    protein_pairs_data = []\n",
    "\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        protein1 = row[0]\n",
    "        protein2 = row[2]\n",
    "        interaction_probability = row[4]\n",
    "\n",
    "        # Efficiently filter and extract relevant data from result_df\n",
    "        row1 = result_df[result_df['UniProt ID'] == protein1][result_df.columns[1:]]\n",
    "        row2 = result_df[result_df['UniProt ID'] == protein2][result_df.columns[1:]]\n",
    "\n",
    "        # Combine protein data and interaction probability into a single row\n",
    "        if not row1.empty and not row2.empty:  # Check for empty DataFrames\n",
    "            combined_row = [protein1, protein2, interaction_probability]\n",
    "            protein_pairs_data.append(combined_row)\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    protein_pairs_df = pd.DataFrame(protein_pairs_data, columns=['Protein1', 'Protein2', 'InteractionProbability'])\n",
    "    return protein_pairs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc1fb1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Protein1     Protein2  InteractionProbability\n",
      "0      CNBP_HUMAN   EBP2_HUMAN                    0.86\n",
      "1     DTBP1_HUMAN  BL1S1_HUMAN                    0.89\n",
      "2      PLK1_HUMAN   PSA3_HUMAN                    0.88\n",
      "3      ATG3_HUMAN  ATG12_HUMAN                    0.90\n",
      "4      CSN8_HUMAN   CSN2_HUMAN                    0.96\n",
      "...           ...          ...                     ...\n",
      "6658  ECHD1_HUMAN   PNPH_HUMAN                    0.49\n",
      "6659  TRI25_HUMAN  SC31A_HUMAN                    0.49\n",
      "6660  PLCB3_HUMAN  SYNJ1_HUMAN                    0.00\n",
      "6661  CU059_HUMAN  HNRH1_HUMAN                    0.49\n",
      "6662   MPCP_HUMAN  RAB7A_HUMAN                    0.49\n",
      "\n",
      "[6663 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "protein_pairs_df = get_protein_pair_df(filtered_df, result_df)\n",
    "print(protein_pairs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f12150a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6663\n"
     ]
    }
   ],
   "source": [
    "print(len(protein_pairs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d7444af0-f17b-41e4-b4c2-9d4eeaac7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_combined_descriptors(protein_seq, protein_pairs_df):\n",
    "    combined_descriptor_rows = []\n",
    "\n",
    "    for _, row in protein_pairs_df.iterrows():\n",
    "        \n",
    "        protein1 = row[0]\n",
    "        protein2 = row[1]\n",
    "        interaction_prob = row[2]\n",
    "        combined_descriptor = get_combined_vector(protein1, protein2, result_df)\n",
    "        combined_descriptor_list = [*combined_descriptor]\n",
    "        # if len(combined_descriptor_list) != 566:\n",
    "        #     continue\n",
    "        combined_descriptor_row = [protein1, protein2, *combined_descriptor_list, interaction_prob]\n",
    "        combined_descriptor_rows.append(combined_descriptor_row)\n",
    "\n",
    "    column_names = [*range(569)]\n",
    "    # column_names = ['protein1', 'protein2'] + column_names + ['interaction_prob']\n",
    "    combined_descriptors_df = pd.DataFrame(combined_descriptor_rows, columns=column_names)\n",
    "    \n",
    "    return combined_descriptors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65715391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142340/2038597615.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  protein1 = row[0]\n",
      "/tmp/ipykernel_142340/2038597615.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  protein2 = row[1]\n",
      "/tmp/ipykernel_142340/2038597615.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  interaction_prob = row[2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0            1         2         3         4         5         6    \\\n",
      "0   CNBP_HUMAN   EBP2_HUMAN  4.376997  0.771170  0.835097  0.866124  0.538495   \n",
      "1  DTBP1_HUMAN  BL1S1_HUMAN  4.355378  0.771795  0.977514  1.020024  0.615780   \n",
      "2   PLK1_HUMAN   PSA3_HUMAN  4.350983  0.921458  0.979215  1.043114  0.606984   \n",
      "3   ATG3_HUMAN  ATG12_HUMAN  4.336443  0.912624  0.937119  0.993354  0.590773   \n",
      "4   CSN8_HUMAN   CSN2_HUMAN  4.363747  0.942411  1.021622  1.081436  0.611850   \n",
      "\n",
      "        7         8         9    ...        559        560        561  \\\n",
      "0  0.699603  0.734220  0.451208  ...  17.306808  12.228814  21.404730   \n",
      "1  0.720567  0.676516  0.444765  ...  17.071913  12.099715  20.790263   \n",
      "2  0.733716  0.684657  0.441700  ...  16.864708  12.034104  20.710379   \n",
      "3  0.731851  0.681708  0.443680  ...  16.242498  11.658963  19.775409   \n",
      "4  0.735120  0.679697  0.439954  ...  17.005705  12.355417  20.585439   \n",
      "\n",
      "         562       563        564       565       566       567   568  \n",
      "0  30.915457  6.094113  22.627251 -0.284131  9.421790  3.108872  0.86  \n",
      "1  31.274987  6.148244  23.480201 -0.339447  9.581870  3.242057  0.89  \n",
      "2  31.093584  6.085997  23.083606 -0.336897  9.525408  3.279343  0.88  \n",
      "3  30.778781  6.057785  23.317048 -0.548705  9.540261  3.432140  0.90  \n",
      "4  31.799906  6.121988  23.693373 -0.373932  9.704056  3.273589  0.96  \n",
      "\n",
      "[5 rows x 569 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interaction_df = calculate_combined_descriptors(protein_sequences, protein_pairs_df)\n",
    "print(interaction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e5590a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interacting pairs: 6663\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of interacting pairs: {len(interaction_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28282a17-de22-4186-a151-74cdd73f8b23",
   "metadata": {},
   "source": [
    "#   Interaction_df gives the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf19a7e7-cd14-4f75-807b-2ad95636a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interacting pairs: 6663\n",
      "           0            1         2         3         4         5         6    \\\n",
      "0   CNBP_HUMAN   EBP2_HUMAN  4.376997  0.771170  0.835097  0.866124  0.538495   \n",
      "1  DTBP1_HUMAN  BL1S1_HUMAN  4.355378  0.771795  0.977514  1.020024  0.615780   \n",
      "2   PLK1_HUMAN   PSA3_HUMAN  4.350983  0.921458  0.979215  1.043114  0.606984   \n",
      "3   ATG3_HUMAN  ATG12_HUMAN  4.336443  0.912624  0.937119  0.993354  0.590773   \n",
      "4   CSN8_HUMAN   CSN2_HUMAN  4.363747  0.942411  1.021622  1.081436  0.611850   \n",
      "\n",
      "        7         8         9    ...        559        560        561  \\\n",
      "0  0.699603  0.734220  0.451208  ...  17.306808  12.228814  21.404730   \n",
      "1  0.720567  0.676516  0.444765  ...  17.071913  12.099715  20.790263   \n",
      "2  0.733716  0.684657  0.441700  ...  16.864708  12.034104  20.710379   \n",
      "3  0.731851  0.681708  0.443680  ...  16.242498  11.658963  19.775409   \n",
      "4  0.735120  0.679697  0.439954  ...  17.005705  12.355417  20.585439   \n",
      "\n",
      "         562       563        564       565       566       567   568  \n",
      "0  30.915457  6.094113  22.627251 -0.284131  9.421790  3.108872  0.86  \n",
      "1  31.274987  6.148244  23.480201 -0.339447  9.581870  3.242057  0.89  \n",
      "2  31.093584  6.085997  23.083606 -0.336897  9.525408  3.279343  0.88  \n",
      "3  30.778781  6.057785  23.317048 -0.548705  9.540261  3.432140  0.90  \n",
      "4  31.799906  6.121988  23.693373 -0.373932  9.704056  3.273589  0.96  \n",
      "\n",
      "[5 rows x 569 columns]\n"
     ]
    }
   ],
   "source": [
    "interaction_df = interaction_df.dropna()\n",
    "print(f\"Number of interacting pairs: {len(interaction_df)}\")\n",
    "print(interaction_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d9512",
   "metadata": {},
   "source": [
    "\n",
    "### Save DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a01981d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df.to_csv('dataframes/interaction_data.csv', index=False)\n",
    "filtered_df.to_csv('dataframes/filtered_data.csv', index=False)\n",
    "result_df.to_csv('dataframes/result_data.csv', index=False)\n",
    "protein_pairs_df.to_csv('dataframes/protein_pairs_data.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
